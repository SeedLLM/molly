<div align="center">
<img width="400" height="240" alt="Image" src="https://github.com/user-attachments/assets/94b8192d-7f5b-49ed-b2fa-861c643b8b7a" />
</div>

## Molly

Molly is a Large Language Model composed of multiple encoders, capable of understanding multi-omics data (DNA, RNA, and protein).

Molly æ˜¯ä¸€ä¸ªé›†æˆäº†å¤šä¸ª encoder çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç†è§£ DNAï¼ŒRNA å’Œ protein åºåˆ—ä¿¡æ¯ã€‚
<img width="994" height="369" alt="Image" src="https://github.com/user-attachments/assets/65b17c06-0506-40a3-bd25-e59172630cff" />
Omics-Specific Modelsï¼ˆOSMsï¼‰æŒ‡ä»£å„è‡ªç»„å­¦èµ›é“ä¸­æ€§èƒ½é¢†å…ˆçš„ä¸“ç”¨æ¨¡å‹ï¼›Enc-Head åˆ™æ˜¯â€œç»„å­¦ Encoder + åˆ†ç±»å¤´â€çš„ç®€æ´æ¶æ„ï¼Œå°†é¢„è®­ç»ƒç¼–ç å™¨ä¸ä»»åŠ¡ç›¸å…³åˆ†ç±»å¤´ç›´æ¥è¿æ¥ã€‚

## :star2: Feature
- **Base Model**: Enhanced [Qwen3](https://github.com/QwenLM/Qwen3) with [nucleotide-transformer](https://github.com/instadeepai/nucleotide-transformer) and [ESM-2](https://github.com/facebookresearch/esm) encoders
- **Optimization**: Support [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) and [FlashAttention](https://github.com/Dao-AILab/flash-attention) for 100% training speedup, see [example script](./scripts/train/examples/run_train_1B_z2_b1.sh)

## ğŸ¤— Download trained model

<div>
  <tr>
      <td><a href="https://huggingface.co/tpoisonooo/MOLLM-1.7B">molly-1.7B</a></td>
      <td><a href="https://huggingface.co/tpoisonooo/MOLLM-4B">molly-4B</a></td>
      <td><a href="https://huggingface.co/tpoisonooo/MOLLM-8B">molly-8B</a></td>
  </tr>
</div>  

## :zap: How to inference

    ```bash
    ./scripts/infer/inference_nt_lora.sh
    ```

## :fire: How to train

1. Hotfix transformers source code

    ```python
    ## transformers/modeling_utils.py
    ## add 4 lines 
        if not model._tp_plan:
            model_tp_plan = {}
        else:
            model_tp_plan = model._tp_plan
    
    ## model._tp_plan -> model_tp_plan
        tp_plan_regex = (
            re.compile("|".join([re.escape(plan) for plan in model_tp_plan]))
            if _torch_distributed_available and torch.distributed.is_initialized()
            else None
        )
    ```

2. Run training script

    ```bash
    swanlab login
    
    ./scripts/train/run_train.sh
    
    # or for test
    ./scripts/train/run_train_mini.sh
    ```

## Eval
* éœ€è¦ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹è¯„æµ‹é›†è¿›è¡Œæ¨ç†
    * è„šæœ¬ä¸­çš„experiment_name, MODEL_DIR, CHECKPOINTéœ€è¦ä¿®æ”¹ä¸ºè®­ç»ƒå¥½æ¨¡å‹çš„è·¯å¾„
    * --text-model-path, --dna-rna-model-path, --protein-model-pathä¸ºå®˜æ–¹é¢„è®­ç»ƒæƒé‡æ–‡ä»¶è·¯å¾„
    * --dataset-pathä¸ºè¯„æµ‹é›†è·¯å¾„
    * --json-fileä¸ºç»“æœè¾“å‡ºè·¯å¾„

```
./scripts/infer/inference_nt_lora.sh
```
* å°†æ¨ç†æ•°æ®è½¬æ¢ä¸ºå¾…æµ‹è¯„çš„æ ¼å¼
    * éœ€è¦ä¿®æ”¹src_pathsä¸dst_pathï¼Œsrc_pathsä¸ºæ¨ç†ç»“æœçš„è·¯å¾„ï¼ˆæ³¨æ„éœ€è¦æ˜¯æ–‡ä»¶å¤¹ï¼‰ï¼Œdst_pathæ˜¯è½¬æ¢åçš„è¾“å‡ºè·¯å¾„ï¼ˆæ³¨æ„æ˜¯jsonæ–‡ä»¶ï¼‰
```
python molly/data_tools/convert.py
````
* ä½¿ç”¨æµ‹è¯„è„šæœ¬è·å¾—æ¨¡å‹åœ¨å„ä¸ªä»»åŠ¡ä¸Šçš„æ€§èƒ½
    * æ­¤å¤„--input_file_pathä¸ºè½¬æ¢åçš„è¾“å‡ºçš„jsonæ–‡ä»¶çš„è·¯å¾„
```
cd molly/eval
.eval.sh
```

## :pushpin: LICENSE

This project follows [apache license](./LICENSE).