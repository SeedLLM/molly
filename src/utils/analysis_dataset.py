"""
data analysis
"""
import os
import json
import random
from typing import List, Dict
from collections import defaultdict

import matplotlib.pyplot as plt 

class JsonlDatasetInspector:
    def __init__(self, file_path: str):
        self.file_path = file_path

    def count_lines(self) -> int:
        """ç»Ÿè®¡ JSONL æ–‡ä»¶çš„æ€»è¡Œæ•°"""
        count = 0
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for _ in f:
                count += 1
        return count

    def preview(self, num_lines: int = 10) -> List[dict]:
        """è¿”å›å¹¶æ‰“å°å‰ num_lines æ¡æ ·æœ¬"""
        samples = []
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= num_lines:
                    break
                try:
                    data = json.loads(line)
                    samples.append(data)
                except json.JSONDecodeError:
                    print(f"ç¬¬ {i+1} è¡Œ JSON è§£ç å¤±è´¥ï¼š{line.strip()}")
        for i, sample in enumerate(samples):
            print(f"\næ ·æœ¬ {i+1}:\n{json.dumps(sample, ensure_ascii=False, indent=2)}")
        return samples

    def count_tasks(self, visualize: bool = True, save_path: str = "task_distribution_pie.png") -> Dict[str, int]:
        """
        ç»Ÿè®¡æ¯ä¸ª task çš„æ ·æœ¬æ•°é‡ï¼Œå¹¶æ‰“å°æ€»ä»»åŠ¡æ•°ã€‚
        å¦‚æœ visualize=Trueï¼Œåˆ™ç»˜åˆ¶é¥¼å›¾ã€‚
        """
        task_counter = defaultdict(int)
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                try:
                    data = json.loads(line)
                    task_name = data.get("task", "UNKNOWN")
                    task_counter[task_name] += 1
                except json.JSONDecodeError:
                    print(f"ç¬¬ {i+1} è¡Œ JSON è§£ç å¤±è´¥ï¼Œè·³è¿‡")

        print("\nä»»åŠ¡ç»Ÿè®¡ç»“æœï¼š")
        for task, count in task_counter.items():
            print(f"{task}: {count} æ¡")
        print(f"\nğŸ“Š æ€»å…± {len(task_counter)} ç§ä»»åŠ¡")

        if visualize:
            labels = list(task_counter.keys())
            sizes = list(task_counter.values())

            # ç”Ÿæˆé¢œè‰²åˆ—è¡¨ä»¥ç¡®ä¿ legend ä¸ wedge ä¸€è‡´
            colors = plt.cm.tab20.colors  # å¯æ¢æˆ tab20b, tab20c, Set3 ç­‰

            plt.figure(figsize=(16, 15))
            wedges, texts, autotexts = plt.pie(
                sizes,
                autopct='%1.1f%%',
                startangle=140,
                colors=colors[:len(sizes)],
                textprops={'fontsize': 8},
            )

            # æ·»åŠ å›¾ä¾‹ legend åœ¨å³è¾¹
            plt.legend(
                wedges,
                labels,
                title="Tasks",
                loc="center left",
                bbox_to_anchor=(1, 0.5),
                fontsize=12,
                title_fontsize=13
            )

            plt.title('Sample Distribution by Task', fontsize=16)
            plt.axis('equal')
            plt.tight_layout()

            # ä¿å­˜å›¾åƒ
            plt.savefig(save_path, bbox_inches="tight")  # é˜²æ­¢å›¾ä¾‹è¢«æˆªæ–­
            print(f"\nâœ… é¥¼å›¾å·²ä¿å­˜åˆ°: {os.path.abspath(save_path)}")


        return dict(task_counter)

    def visualize_per_task(self, num_samples_per_task: int = 3) -> Dict[str, List[dict]]:
        """
        æŒ‰ task æŠ½å–æŒ‡å®šæ•°é‡æ ·æœ¬ï¼Œå¹¶æ‰“å°å±•ç¤º
        è¿”å›æ¯ä¸ª task å¯¹åº”çš„æ ·æœ¬åˆ—è¡¨
        """
        task_samples = defaultdict(list)
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                try:
                    data = json.loads(line)
                    task = data.get("task", "UNKNOWN")
                    if len(task_samples[task]) < num_samples_per_task:
                        task_samples[task].append(data)
                except json.JSONDecodeError:
                    continue

        for task, samples in task_samples.items():
            print(f"\nã€ä»»åŠ¡: {task}ã€‘å±•ç¤ºå‰ {len(samples)} æ¡æ ·æœ¬:")
            for i, sample in enumerate(samples):
                print(f"\n  æ ·æœ¬ {i+1}:\n{json.dumps(sample, ensure_ascii=False, indent=2)}")

        return dict(task_samples)
        
    def extract_n_samples_per_task(self, n: int, output_file: str, random_seed: int = 42, shuffle: bool = True) -> Dict[str, List[dict]]:
        """
        ä¸ºæ¯ä¸ªä»»åŠ¡æŠ½å–næ¡æ ·æœ¬ï¼Œå¹¶å°†æ‰€æœ‰æ ·æœ¬å†™å…¥æ–°çš„JSONLæ–‡ä»¶
        
        Args:
            n: æ¯ä¸ªä»»åŠ¡éœ€è¦æŠ½å–çš„æ ·æœ¬æ•°é‡
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            random_seed: éšæœºç§å­ï¼Œç”¨äºéšæœºæŠ½æ ·
            shuffle: æ˜¯å¦æ‰“ä¹±æœ€ç»ˆçš„æ ·æœ¬é¡ºåº
            
        Returns:
            ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºè¯¥ä»»åŠ¡æŠ½å–çš„æ ·æœ¬åˆ—è¡¨
        """
        # åˆå§‹åŒ–éšæœºæ•°ç”Ÿæˆå™¨
        random.seed(random_seed)
        
        # æ”¶é›†æ¯ä¸ªä»»åŠ¡çš„æ‰€æœ‰æ ·æœ¬
        all_task_samples = defaultdict(list)
        
        print(f"æ­£åœ¨è¯»å–å¹¶æŒ‰ä»»åŠ¡åˆ†ç±»æ ·æœ¬...")
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                try:
                    data = json.loads(line)
                    task = data.get("task", "UNKNOWN")
                    all_task_samples[task].append(data)
                except json.JSONDecodeError:
                    print(f"ç¬¬ {i+1} è¡Œ JSON è§£ç å¤±è´¥ï¼Œè·³è¿‡")
        
        # ä¸ºæ¯ä¸ªä»»åŠ¡æŠ½å–nä¸ªæ ·æœ¬
        selected_samples = {}
        total_selected = 0
        
        for task, samples in all_task_samples.items():
            # å¦‚æœæ ·æœ¬æ•°å°äºnï¼Œå…¨éƒ¨ä¿ç•™ï¼›å¦åˆ™éšæœºæŠ½å–nä¸ª
            if len(samples) <= n:
                selected = samples
            else:
                selected = random.sample(samples, n)
            
            selected_samples[task] = selected
            total_selected += len(selected)
            print(f"ä»»åŠ¡ '{task}': ä» {len(samples)} æ¡æ ·æœ¬ä¸­æŠ½å–äº† {len(selected)} æ¡")
        
        # å°†æ‰€æœ‰æ ·æœ¬åˆå¹¶åˆ°ä¸€ä¸ªåˆ—è¡¨
        all_selected = []
        for task_samples in selected_samples.values():
            all_selected.extend(task_samples)
        
        # å¯é€‰ï¼šæ‰“ä¹±æ ·æœ¬é¡ºåº
        if shuffle:
            random.shuffle(all_selected)
        
        # å†™å…¥æ–°æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            for sample in all_selected:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        print(f"\nâœ… å·²æˆåŠŸæŠ½å– {total_selected} æ¡æ ·æœ¬ï¼ˆæ¥è‡ª {len(selected_samples)} ä¸ªä»»åŠ¡ï¼‰ï¼Œå¹¶ä¿å­˜åˆ°: {os.path.abspath(output_file)}")
        return selected_samples

if __name__ == "__main__":
    # åˆå§‹åŒ–
    train_file = "/tos-bjml-ai4agr/lijinzhe/dataset/BioMLLM/train_only_dna.jsonl"
    test_file = "/tos-bjml-ai4agr/lijinzhe/dataset/BioMLLM/dev_only_dna.jsonl"
    inspector = JsonlDatasetInspector(train_file)
    # ç»Ÿè®¡æ ·æœ¬æ€»æ•°
    total = inspector.count_lines()
    print(f"\næ€»æ ·æœ¬æ•°: {total}")
    # æŸ¥çœ‹å‰ 5 æ¡æ ·æœ¬
    # inspector.preview(num_lines=3)
    # ç»Ÿè®¡å„ä¸ª task çš„æ ·æœ¬åˆ†å¸ƒ
    task_stats = inspector.count_tasks(visualize=True, save_path="train_task_pie.png")
    # æŒ‰æ¯ä¸ªä»»åŠ¡æ‰“å°æœ€å¤š 3 æ¡æ ·æœ¬
    # inspector.visualize_per_task(num_samples_per_task=1)
    
    # ä¸ºæ¯ä¸ªä»»åŠ¡æŠ½å–10æ¡æ ·æœ¬ï¼Œåˆ›å»ºä¸€ä¸ªå¹³è¡¡æ•°æ®é›†
    inspector.extract_n_samples_per_task(500, output_file="balanced_dna_train_dataset.jsonl")


